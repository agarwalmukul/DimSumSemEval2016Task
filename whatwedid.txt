In order to predict MWEs and supersenses better, we first added some basic features including word, pos and lemma sequences up to length 3 as well parent distance and pos.  This was used to include basic context and dependency information about the sentence and possible phrases.  We also used wordnet. We peeked ahead to see if there was an exact match with any known MWE in the provided list.  We also took wornet's hypernym as an feature to help with supersense predition. In addition to these, we checked for things like whether the word and words nearby it were capitalized or numbers since the paper linked mentioned this could be helpful and was potentially an indicator of the word being part of a name or a certain location or entity. 

We also tried to add the LDF features and expand to the full dimsum task, both of those are in the fulldimsum.py file and there is no test prediction output file unfortunately. To do this we expanded the bio class again, but compute_reference became much more complicated as the number of off track sequences increased alot. They were also instances that seemed a lot harder to resolve.  What we have here was just a start, and we assume that all off track sequences should sync with the annotation.
